import { ChatMessage, Completions, ImageGenerations } from "../../generated/src/models/models.js";
import { GetChatCompletionsWithAzureExtensionsOptions, GetCompletionsOptions, GetChatCompletionsOptions as GeneratedGetChatCompletionsOptions } from "../../generated/src/models/options.js";
import { OpenAIContext as Client, GetChatCompletions200Response, GetChatCompletionsDefaultResponse, GetChatCompletionsWithAzureExtensions200Response, GetChatCompletionsWithAzureExtensionsDefaultResponse } from "../../generated/src/rest/index.js";
import { StreamableMethod } from "@azure-rest/core-client";
import { ChatCompletions } from "../models/models.js";
import { GetChatCompletionsOptions } from "./models.js";
import { ImageGenerationOptions } from "../models/options.js";
import { AudioResult, AudioResultFormat, AudioResultSimpleJson, GetAudioTranscriptionOptions, GetAudioTranslationOptions } from "../models/audio.js";
export declare function listCompletions(context: Client, prompt: string[], deploymentName: string, options?: GetCompletionsOptions): AsyncIterable<Omit<Completions, "usage">>;
export declare function getImages(context: Client, prompt: string, options?: ImageGenerationOptions): Promise<ImageGenerations>;
export declare function listChatCompletions(context: Client, messages: ChatMessage[], deploymentName: string, options?: GetChatCompletionsOptions): AsyncIterable<ChatCompletions>;
/**
 * Gets chat completions for the provided chat messages.
 * Completions support a wide variety of tasks and generate text that continues from or "completes"
 * provided prompt data.
 */
export declare function getChatCompletions(context: Client, messages: ChatMessage[], deploymentId: string, options?: GetChatCompletionsOptions): Promise<ChatCompletions>;
/**
 * Returns the translation of an audio file.
 * @param context - The context containing the client to use for this request.
 * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
 * @param fileContent - The content of the audio file to translate.
 * @param options - The options for this audio translation request.
 * @returns The audio translation result.
 */
export declare function getAudioTranslation(context: Client, deploymentName: string, fileContent: Uint8Array, options?: GetAudioTranslationOptions): Promise<AudioResultSimpleJson>;
/**
 * Returns the translation of an audio file.
 * @param context - The context containing the client to use for this request.
 * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
 * @param fileContent - The content of the audio file to translate.
 * @param format - The format of the result object. See {@link AudioResultFormat} for possible values.
 * @param options - The options for this audio translation request.
 * @returns The audio translation result.
 */
export declare function getAudioTranslation<Format extends AudioResultFormat>(context: Client, deploymentName: string, fileContent: Uint8Array, format: Format, options?: GetAudioTranslationOptions): Promise<AudioResult<Format>>;
/**
 * Returns the transcription of an audio file in a simple JSON format.
 * @param context - The context containing the client to use for this request.
 * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
 * @param fileContent - The content of the audio file to transcribe.
 * @param options - The options for this audio transcription request.
 * @returns The audio transcription result in a simple JSON format.
 */
export declare function getAudioTranscription(context: Client, deploymentName: string, fileContent: Uint8Array, options?: GetAudioTranscriptionOptions): Promise<AudioResultSimpleJson>;
/**
 * Returns the transcription of an audio file.
 * @param context - The context containing the client to use for this request.
 * @param deploymentName - The name of the model deployment (when using Azure OpenAI) or model name (when using non-Azure OpenAI) to use for this request.
 * @param fileContent - The content of the audio file to transcribe.
 * @param format - The format of the result object. See {@link AudioResultFormat} for possible values.
 * @param options - The options for this audio transcription request.
 * @returns The audio transcription result in a format of your choice.
 */
export declare function getAudioTranscription<Format extends AudioResultFormat>(context: Client, deploymentName: string, fileContent: Uint8Array, format: Format, options?: GetAudioTranscriptionOptions): Promise<AudioResult<Format>>;
export declare function _getChatCompletionsWithAzureExtensionsSend(context: Client, messages: ChatMessage[], deploymentId: string, options?: GetChatCompletionsWithAzureExtensionsOptions): StreamableMethod<GetChatCompletionsWithAzureExtensions200Response | GetChatCompletionsWithAzureExtensionsDefaultResponse>;
export declare function _getChatCompletionsSend(context: Client, messages: ChatMessage[], deploymentId: string, options?: GeneratedGetChatCompletionsOptions): StreamableMethod<GetChatCompletions200Response | GetChatCompletionsDefaultResponse>;
//# sourceMappingURL=operations.d.ts.map